<발표 내용>

1. introduction
안녕하세요 your cartoon is team입니다.
먼저 저희 팀 주제를 간단히 말씀드리면 사진이나 동영상을 컷툰으로 바꾸어주는 딥러닝모델을 개발하여
어플리케이션으로 서비스를 제공하는 것이었습니다.

2. algorithm&proposed system
시스템 도식화를 보면서 알고리즘을 설명드리자면 
사용자가 어플리케이션에 동영상을 업로드하면 동영상에서 프레임을 뽑아 이미지를 만들고
그 프레임속의 색깔과 명암으로 유사도를 측정하여 클러스터링을 합니다. 
사진 갯수가 일정기준이상이 되는 클러스터에서만 그 클러스터를 대표하는 key-frame을 뽑습니다.

이렇게 뽑은 key-frame을 서버로 전송하면 서버에서 미리 학습시켜놓은 Mask R-CNN이 
이미지 속의 인스턴스들을 구분해내어 instance mask를 생성한후 
masked image와 원본이미지를 인스턴스의 모양 및 화풍을 변화시키는 모델에 입력으로 넣어
사진을 변환합니다.

이렇게 변환된 이미지를 다시 어플리케이션으로 보내 사용자가 고른 레이아웃에 맞추어 만화로 만듭니다.

3. test
저희는 key-frame extraction 까지 구현을 했고 실제 동영상을 넣어 test를 해보았습니다. 
60초짜리 동영상을 input으로 넣었을 때 파라미터에 따라 나오는 프레임이 달라지는 것을 볼 수 있습니다
임계값(offset) ; 낮을수록 유사도 낮아도 같은 클러스터로 들어감 / 크면 유사도가 커야 같은 클러스터로 들어감
키frame 뽑는 기준(전체 프레임의 몇 percent인지) : 10%너무 크고 0.03..이 적당한듯

3.1 test_result1 : 임계값 : 6, 기준: 0.02 -> 3컷

3.2 test_result2 : 임계값 : 8, 기준: 0.01 -> 12컷

offset 6이상으로 넘어가면 시간 너무 오래걸림 but 클러스터 양 많아져서 기준 0.01로 낮추니까 컷이 잘나옴

4. complement = 보완점
동영상의 내용을 최대한 다 보여줄수 있는 파라미터를 설정하는것을 더 고민해봐야함

5. remaining system

5.1 Mask R-CNN

5.2 Insta & Cartoon GAN
 
5.3 Application 구현

6. expected output