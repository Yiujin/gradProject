{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darkflow.net.build import TFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leehyun\\desktop\\jupyter\\ketframe\\darknet\\darkflow\n"
     ]
    }
   ],
   "source": [
    "cd ./darknet/darkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolov2.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.05582141876220703s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 8.96701693534851s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'model' : 'cfg/yolo.cfg',\n",
    "    'load' : 'bin/yolov2.weights',\n",
    "    'threshold' : 0.3,\n",
    "}\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.feature import greycomatrix,greycoprops\n",
    "\n",
    "class Key_Frame_Extraction:\n",
    "    def __init__(self,offset):\n",
    "        self.numCluster = 1\n",
    "        self.Cluster = []\n",
    "        self.centroid = []\n",
    "        self.a = offset\n",
    "    \n",
    "    def get_GLCM_Feature(self,g):\n",
    "        gl = np.array([\n",
    "        greycoprops(g, 'contrast'),\n",
    "        greycoprops(g, 'homogeneity'),\n",
    "        greycoprops(g, 'energy'),\n",
    "        greycoprops(g, 'correlation')])\n",
    "        return gl\n",
    "    \n",
    "    def get_Frame(self,video_path):\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        test_image_set = []\n",
    "        count = 0\n",
    "        frame_count = 0\n",
    "        while(vidcap.isOpened):\n",
    "            ret, image = vidcap.read()\n",
    "            #print(ret)\n",
    "            if ret:\n",
    "                count +=1\n",
    "                if count%10 == 0:\n",
    "                    frame_count+=1\n",
    "                    test_image_set.append(cv2.cvtColor(image,cv2.COLOR_RGB2HSV))\n",
    "                    #print(f\"frame {frame_count}\")\n",
    "            else:\n",
    "                    break\n",
    "        vidcap.release()\n",
    "        return test_image_set\n",
    "        \n",
    "    def CombineSimilarity(self,img,centroid):\n",
    "        hist = cv2.calcHist([img],[0,1],None,[180,256],[0,180,0,256])\n",
    "        hist = cv2.normalize(hist,hist).flatten()\n",
    "        HisSimilarity = np.array([ cv2.compareHist(hist,x[1],cv2.HISTCMP_INTERSECT) for x in centroid])\n",
    "\n",
    "        glcm= greycomatrix(cv2.cvtColor(img,cv2.COLOR_RGB2GRAY),[1],[0],symmetric = True,normed = True)\n",
    "        glcm = self.get_GLCM_Feature(glcm)\n",
    "        GLCMSimilarity = np.array([np.sum((glcm - x[2])**2)**0.5 for x in centroid])\n",
    "\n",
    "        return 0.7*HisSimilarity - 0.3*GLCMSimilarity\n",
    "    \n",
    "    def get_KeyFrame(self,frame_set):\n",
    "        train_x = frame_set\n",
    "        \n",
    "        self.Cluster.append([train_x[0]])\n",
    "        hist = cv2.calcHist([train_x[0]],[0,1],None,[180,256],[0,180,0,256])\n",
    "        g = greycomatrix(cv2.cvtColor(train_x[0],cv2.COLOR_RGB2GRAY),[1],[0],symmetric = True,normed = True)\n",
    "                         \n",
    "        self.centroid.append([train_x[0],cv2.normalize(hist,hist).flatten(),self.get_GLCM_Feature(g)])\n",
    "        for idx,x in enumerate(train_x[1:]):\n",
    "            result = self.CombineSimilarity(x,self.centroid)\n",
    "\n",
    "            s = np.max(result)\n",
    "            maxidx = np.argmax(result)\n",
    "            #print(f'{s} ')\n",
    "            if(s > self.a):\n",
    "                #print(f'Cluster idx : {maxidx}')\n",
    "                self.Cluster[maxidx].append(x)\n",
    "                numFrame = len(self.Cluster[maxidx])\n",
    "                hist = cv2.calcHist([self.Cluster[maxidx][numFrame//2]],[0,1],None,[180,256],[0,180,0,256])\n",
    "                g = greycomatrix(cv2.cvtColor(self.Cluster[maxidx][numFrame//2],cv2.COLOR_RGB2GRAY),[1],[0],symmetric = True,normed = True)        \n",
    "                self.centroid[maxidx] = [self.Cluster[maxidx][numFrame//2],cv2.normalize(hist,hist).flatten(),self.get_GLCM_Feature(g)]\n",
    "            else:\n",
    "                #print(f'Cluster idx : {self.numCluster}')\n",
    "                self.Cluster.append([x])\n",
    "                self.numCluster+=1\n",
    "                hist = cv2.calcHist([x],[0,1],None,[180,256],[0,180,0,256])\n",
    "                g = greycomatrix(cv2.cvtColor(x,cv2.COLOR_RGB2GRAY),[1],[0],symmetric = True,normed = True)\n",
    "                self.centroid.append([x,cv2.normalize(hist,hist).flatten(),self.get_GLCM_Feature(g)])\n",
    "        result= []\n",
    "        for i in range(len(cl.centroid)):\n",
    "            result_object = tfnet.return_predict(self.centroid[i][0])\n",
    "            result_object = [ x['label'] for x in result_object]\n",
    "            weight = len(cl.Cluster[i])\n",
    "            if 'person' in result_object:\n",
    "                weight += 3\n",
    "            if weight >= len(train_x)*0.03:\n",
    "                result.append(cv2.cvtColor(self.centroid[i][0],cv2.COLOR_HSV2RGB))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leehyun\\desktop\\jupyter\\ketframe\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Key_Frame_Extraction(offset = 1)\n",
    "Frame_set = cl.get_Frame(\"./test_video1.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Frame_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.478180408477783\n"
     ]
    }
   ],
   "source": [
    "before = time.time()\n",
    "Key_Frame = cl.get_KeyFrame(Frame_set)\n",
    "print(time.time()-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Key_Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(Key_Frame)):\n",
    "    print(i)\n",
    "    cv2.imwrite('test_image_' + str(count) + '.jpg',Key_Frame[i])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
